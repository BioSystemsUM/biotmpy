{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= 'hp_han'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: biotmpygpu\n",
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import os\n",
    "import tensorflow \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "global seed_value\n",
    "seed_value = 123123\n",
    "#seed_value = None\n",
    "\n",
    "environment_name = sys.executable.split('/')[-3]\n",
    "print('Environment:', environment_name)\n",
    "os.environ[environment_name] = str(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tensorflow.random.set_seed(seed_value)\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "multiple_gpus = [0,1,2,3]\n",
    "#multiple_gpus = None\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('hp_results'):\n",
    "    print('a')\n",
    "    os.mkdir('hp_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/malves/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/malves/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/malves/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if multiple_gpus:\n",
    "    devices = []\n",
    "    for gpu in multiple_gpus:\n",
    "        devices.append('/gpu:' + str(gpu))    \n",
    "    strategy = tensorflow.distribute.MirroredStrategy(devices=devices)\n",
    "\n",
    "else:\n",
    "    # Get the GPU device name.\n",
    "    device_name = tensorflow.test.gpu_device_name()\n",
    "    # The device name should look like the following:\n",
    "    if device_name == '/device:GPU:0':\n",
    "        print('Using GPU: {}'.format(device_name))\n",
    "    else:\n",
    "        raise SystemError('GPU device not found')\n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = device_name\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "from wrappers.bioc_wrapper import bioc_to_docs, bioc_to_relevances\n",
    "from wrappers.pandas_wrapper import relevances_to_pandas, docs_to_pandasdocs\n",
    "from mlearning.dl import DL_preprocessing\n",
    "from mlearning.dl_models import Hierarchical_Attention_GRU, Hierarchical_Attention_LSTM,Hierarchical_Attention_LSTM2, Hierarchical_Attention_LSTM3\n",
    "from mlearning.dl_models import Hierarchical_Attention_Context\n",
    "from mlearning.dl_models import DeepDTA\n",
    "from mlearning.embeddings import compute_embedding_matrix, glove_embeddings_2\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from mlearning.dl import plot_training_history\n",
    "from mlearning.config import Config\n",
    "from mlearning.dl import average_precision\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from mlearning.dl import plot_roc_n_pr_curves\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, LSTM, RNN, Bidirectional, Flatten, Activation, \\\n",
    "    RepeatVector, Permute, Multiply, Lambda, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlearning.attention import AttentionLayer\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import TimeDistributed, GRU\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adagrad, Adam, SGD\n",
    "from transformers import TFBertModel\n",
    "from mlearning.attention_context import AttentionWithContext\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from transformers import TFBertForSequenceClassification, BertConfig\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from kerastuner import Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = '../datasets/PMtask_Triage_TrainingSet.xml'\n",
    "test_dataset_path = '../datasets/PMtask_Triage_TestSet.xml'\n",
    "\n",
    "\n",
    "\n",
    "config = Config(model_name=model_name, seed_value=seed_value)\n",
    "config.stop_words = set(stopwords.words('english'))           \n",
    "#config.stop_words = None\n",
    "config.lower = True               \n",
    "config.remove_punctuation = False\n",
    "config.split_by_hyphen = True\n",
    "config.lemmatization = False           \n",
    "config.stems = False                      \n",
    "\n",
    "\n",
    "docs_train = bioc_to_docs(train_dataset_path, config=config)\n",
    "relevances_train = bioc_to_relevances(train_dataset_path, 'protein-protein')\n",
    "\n",
    "\n",
    "x_train_df = docs_to_pandasdocs(docs_train)\n",
    "y_train_df = relevances_to_pandas(x_train_df, relevances_train)\n",
    "\n",
    "#Parameters\n",
    "config.padding = 'post'            #'pre' -> default; 'post' -> alternative\n",
    "config.truncating = 'post'         #'pre' -> default; 'post' -> alternative      #####\n",
    "config.oov_token = 'OOV'\n",
    "\n",
    "config.max_sent_len = 50      #sentences will have a maximum of \"max_sent_len\" words    #400/500\n",
    "config.max_nb_words = 100_000      #it will only be considered the top \"max_nb_words\" words in the dataset\n",
    "config.max_nb_sentences = 15    # set only for the hierarchical attention model!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.embeddings = 'biowordvec'\n",
    "config.embedding_path = './embeddings/12551780'\n",
    "config.embedding_dim = 200\n",
    "config.embedding_format = 'word2vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30020 unique tokens.\n",
      "Index of Unknown Words: 1\n",
      "Training set with 3674 samples\n",
      "Validation set with 408 samples\n",
      "Creating Embedding Matrix...\n",
      "Embedding Matrix Created \n",
      "------------------------\n",
      "number of null word embeddings: 3025 in a total of 30020 words (10.08%)\n",
      "words not found: 0\n"
     ]
    }
   ],
   "source": [
    "config.tokenizer = text.Tokenizer(num_words=config.max_nb_words, oov_token=config.oov_token)\n",
    "\n",
    "x_train, y_train, x_val, y_val = DL_preprocessing(x_train_df, y_train_df,\n",
    "    config=config, dataset='train',\n",
    "    validation_percentage=10,\n",
    "    seed_value=config.seed_value)\n",
    "\n",
    "\n",
    "\n",
    "config.embedding_matrix = compute_embedding_matrix(config, embeddings_format = config.embedding_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global max_sent_len, max_nb_sentences, vocab_size, embed_dim, embedding_matrix\n",
    "max_sent_len = config.max_sent_len\n",
    "max_nb_sentences = config.max_nb_sentences\n",
    "vocab_size = config.embedding_matrix.shape[0]\n",
    "embed_dim = config.embedding_matrix.shape[1]\n",
    "embedding_matrix = config.embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Han_hyper(hp):\n",
    "    embedding_layer = Embedding(vocab_size, embed_dim, weights=[embedding_matrix],\n",
    "                                input_length=max_sent_len, trainable=False, name='word_embedding')\n",
    "    \n",
    "    \n",
    "    word_input = Input(shape=(max_sent_len,), dtype='int32')\n",
    "    word = embedding_layer(word_input)\n",
    "    \n",
    "    word = SpatialDropout1D(rate=hp.Float('dropout_1', min_value=0.0, max_value=0.5, default=0.2, step=0.1), seed=seed_value)(word)\n",
    "    \n",
    "    \n",
    "    layer_1 = hp.Choice('layer_1',['lstm', 'gru'])\n",
    "    layer_1_units = hp.Choice('layer1_units', values=[64,128,256,512], default=128)\n",
    "\n",
    "    if layer_1 == 'lstm':\n",
    "        word = Bidirectional(LSTM(layer_1_units, return_sequences=True))(word)\n",
    "    elif layer_1 == 'gru':\n",
    "        word = Bidirectional(GRU(layer_1_units, return_sequences=True))(word)\n",
    "\n",
    "    word_out = AttentionWithContext()(word)\n",
    "    wordEncoder = Model(word_input, word_out)\n",
    "\n",
    "    \n",
    "    sente_input = Input(shape=(max_nb_sentences, max_sent_len), dtype='int32')\n",
    "    sente = TimeDistributed(wordEncoder)(sente_input)\n",
    "    sente = SpatialDropout1D(rate=hp.Float('dropout_2', min_value=0.0, max_value=0.5, default=0.2, step=0.1),\n",
    "                             seed = seed_value)(sente)\n",
    "    \n",
    "    \n",
    "    layer_2 = hp.Choice('layer_2', values=['lstm', 'gru'])\n",
    "    layer_2_units = hp.Choice('layer2_units', values=[64,128,256,512], default=128)\n",
    "    if layer_2 == 'lstm':\n",
    "        sente = Bidirectional(LSTM(layer_2_units, return_sequences=True))(sente)\n",
    "    elif layer_2 == 'gru':\n",
    "        sente = Bidirectional(GRU(layer_2_units, return_sequences=True))(sente)\n",
    "    sente = AttentionWithContext()(sente)\n",
    "    preds = Dense(1, activation='sigmoid')(sente)\n",
    "    model = Model(sente_input, preds)\n",
    "    \n",
    "    optimizer_value = hp.Choice('optimizer_name', values=[ 'adagrad', 'rmsprop','adam', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    if optimizer_value=='adagrad':\n",
    "        optimizer=Adagrad(lr=learning_rate)\n",
    "    elif optimizer_value=='adam':\n",
    "        optimizer=Adam(lr=learning_rate)\n",
    "    elif optimizer_value=='rmsprop':\n",
    "        optimizer=RMSprop(lr=learning_rate)\n",
    "    elif optimizer_value=='sgd':\n",
    "        optimizer=SGD(lr=learning_rate)\n",
    "\n",
    "        \n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 15, 50)]          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 15, 256)           6407144   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 15, 256)           394240    \n",
      "_________________________________________________________________\n",
      "attention_with_context_1 (At (None, 256)               66048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 6,867,689\n",
      "Trainable params: 863,489\n",
      "Non-trainable params: 6,004,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 15, 50)]          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 15, 1024)          9248232   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 15, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 15, 512)           2623488   \n",
      "_________________________________________________________________\n",
      "attention_with_context_1 (At (None, 512)               263168    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 12,135,401\n",
      "Trainable params: 6,131,201\n",
      "Non-trainable params: 6,004,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.65 - ETA: 10s - loss: 0.6915 - accuracy: 0.609 - ETA: 13s - loss: 0.6898 - accuracy: 0.593 - ETA: 15s - loss: 0.6851 - accuracy: 0.617 - ETA: 16s - loss: 0.6828 - accuracy: 0.612 - ETA: 16s - loss: 0.6934 - accuracy: 0.583 - ETA: 17s - loss: 0.6931 - accuracy: 0.571 - ETA: 17s - loss: 0.6919 - accuracy: 0.574 - ETA: 17s - loss: 0.6917 - accuracy: 0.572 - ETA: 17s - loss: 0.6914 - accuracy: 0.571 - ETA: 17s - loss: 0.6918 - accuracy: 0.568 - ETA: 17s - loss: 0.6917 - accuracy: 0.565 - ETA: 17s - loss: 0.6904 - accuracy: 0.572 - ETA: 17s - loss: 0.6911 - accuracy: 0.571 - ETA: 17s - loss: 0.6890 - accuracy: 0.579 - ETA: 17s - loss: 0.6902 - accuracy: 0.574 - ETA: 17s - loss: 0.6893 - accuracy: 0.575 - ETA: 17s - loss: 0.6898 - accuracy: 0.571 - ETA: 17s - loss: 0.6885 - accuracy: 0.577 - ETA: 16s - loss: 0.6882 - accuracy: 0.576 - ETA: 16s - loss: 0.6863 - accuracy: 0.581 - ETA: 16s - loss: 0.6832 - accuracy: 0.586 - ETA: 16s - loss: 0.6860 - accuracy: 0.584 - ETA: 16s - loss: 0.6852 - accuracy: 0.585 - ETA: 16s - loss: 0.6831 - accuracy: 0.590 - ETA: 16s - loss: 0.6841 - accuracy: 0.588 - ETA: 15s - loss: 0.6844 - accuracy: 0.585 - ETA: 15s - loss: 0.6843 - accuracy: 0.584 - ETA: 15s - loss: 0.6841 - accuracy: 0.585 - ETA: 15s - loss: 0.6820 - accuracy: 0.589 - ETA: 15s - loss: 0.6829 - accuracy: 0.587 - ETA: 15s - loss: 0.6819 - accuracy: 0.589 - ETA: 14s - loss: 0.6814 - accuracy: 0.590 - ETA: 14s - loss: 0.6805 - accuracy: 0.591 - ETA: 14s - loss: 0.6819 - accuracy: 0.590 - ETA: 14s - loss: 0.6811 - accuracy: 0.591 - ETA: 14s - loss: 0.6815 - accuracy: 0.590 - ETA: 14s - loss: 0.6818 - accuracy: 0.588 - ETA: 14s - loss: 0.6818 - accuracy: 0.588 - ETA: 13s - loss: 0.6815 - accuracy: 0.589 - ETA: 13s - loss: 0.6809 - accuracy: 0.589 - ETA: 13s - loss: 0.6805 - accuracy: 0.590 - ETA: 13s - loss: 0.6802 - accuracy: 0.590 - ETA: 13s - loss: 0.6824 - accuracy: 0.585 - ETA: 12s - loss: 0.6824 - accuracy: 0.583 - ETA: 12s - loss: 0.6827 - accuracy: 0.580 - ETA: 12s - loss: 0.6826 - accuracy: 0.581 - ETA: 12s - loss: 0.6825 - accuracy: 0.582 - ETA: 12s - loss: 0.6825 - accuracy: 0.581 - ETA: 12s - loss: 0.6819 - accuracy: 0.582 - ETA: 11s - loss: 0.6818 - accuracy: 0.582 - ETA: 11s - loss: 0.6816 - accuracy: 0.581 - ETA: 11s - loss: 0.6816 - accuracy: 0.578 - ETA: 11s - loss: 0.6815 - accuracy: 0.580 - ETA: 11s - loss: 0.6813 - accuracy: 0.580 - ETA: 11s - loss: 0.6815 - accuracy: 0.579 - ETA: 10s - loss: 0.6808 - accuracy: 0.583 - ETA: 10s - loss: 0.6800 - accuracy: 0.586 - ETA: 10s - loss: 0.6790 - accuracy: 0.586 - ETA: 10s - loss: 0.6794 - accuracy: 0.586 - ETA: 10s - loss: 0.6786 - accuracy: 0.588 - ETA: 9s - loss: 0.6791 - accuracy: 0.587 - ETA: 9s - loss: 0.6788 - accuracy: 0.58 - ETA: 9s - loss: 0.6781 - accuracy: 0.58 - ETA: 9s - loss: 0.6785 - accuracy: 0.58 - ETA: 9s - loss: 0.6775 - accuracy: 0.59 - ETA: 9s - loss: 0.6775 - accuracy: 0.58 - ETA: 8s - loss: 0.6770 - accuracy: 0.58 - ETA: 8s - loss: 0.6772 - accuracy: 0.58 - ETA: 8s - loss: 0.6766 - accuracy: 0.59 - ETA: 8s - loss: 0.6769 - accuracy: 0.59 - ETA: 8s - loss: 0.6759 - accuracy: 0.59 - ETA: 7s - loss: 0.6755 - accuracy: 0.59 - ETA: 7s - loss: 0.6765 - accuracy: 0.59 - ETA: 7s - loss: 0.6761 - accuracy: 0.59 - ETA: 7s - loss: 0.6759 - accuracy: 0.59 - ETA: 7s - loss: 0.6756 - accuracy: 0.59 - ETA: 6s - loss: 0.6759 - accuracy: 0.59 - ETA: 6s - loss: 0.6753 - accuracy: 0.59 - ETA: 6s - loss: 0.6750 - accuracy: 0.59 - ETA: 6s - loss: 0.6745 - accuracy: 0.59 - ETA: 6s - loss: 0.6743 - accuracy: 0.59 - ETA: 6s - loss: 0.6742 - accuracy: 0.59 - ETA: 5s - loss: 0.6739 - accuracy: 0.59 - ETA: 5s - loss: 0.6736 - accuracy: 0.59 - ETA: 5s - loss: 0.6737 - accuracy: 0.59 - ETA: 5s - loss: 0.6737 - accuracy: 0.59 - ETA: 5s - loss: 0.6739 - accuracy: 0.59 - ETA: 4s - loss: 0.6730 - accuracy: 0.59 - ETA: 4s - loss: 0.6728 - accuracy: 0.59 - ETA: 4s - loss: 0.6721 - accuracy: 0.59 - ETA: 4s - loss: 0.6715 - accuracy: 0.59 - ETA: 4s - loss: 0.6716 - accuracy: 0.59 - ETA: 3s - loss: 0.6713 - accuracy: 0.59 - ETA: 3s - loss: 0.6709 - accuracy: 0.59 - ETA: 3s - loss: 0.6709 - accuracy: 0.59 - ETA: 3s - loss: 0.6705 - accuracy: 0.59 - ETA: 3s - loss: 0.6696 - accuracy: 0.59 - ETA: 3s - loss: 0.6692 - accuracy: 0.59 - ETA: 2s - loss: 0.6692 - accuracy: 0.59 - ETA: 2s - loss: 0.6690 - accuracy: 0.59 - ETA: 2s - loss: 0.6690 - accuracy: 0.59 - ETA: 2s - loss: 0.6686 - accuracy: 0.59 - ETA: 2s - loss: 0.6678 - accuracy: 0.59 - ETA: 1s - loss: 0.6681 - accuracy: 0.59 - ETA: 1s - loss: 0.6672 - accuracy: 0.60 - ETA: 1s - loss: 0.6674 - accuracy: 0.59 - ETA: 1s - loss: 0.6667 - accuracy: 0.60 - ETA: 1s - loss: 0.6673 - accuracy: 0.60 - ETA: 0s - loss: 0.6674 - accuracy: 0.60 - ETA: 0s - loss: 0.6673 - accuracy: 0.60 - ETA: 0s - loss: 0.6670 - accuracy: 0.60 - ETA: 0s - loss: 0.6659 - accuracy: 0.60 - ETA: 0s - loss: 0.6655 - accuracy: 0.60 - ETA: 0s - loss: 0.6653 - accuracy: 0.60 - 28s 245ms/step - loss: 0.6653 - accuracy: 0.6045 - val_loss: 0.6242 - val_accuracy: 0.6422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 48a6d1d8eaba0b72cfd3f0c5356b39a9</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6421568393707275</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-layer1_units: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-layer2_units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-layer_1: gru</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-layer_2: lstm</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer_name: rmsprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 15, 50)]          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 15, 512)           6970856   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 15, 128)           295424    \n",
      "_________________________________________________________________\n",
      "attention_with_context_1 (At (None, 128)               16640     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,283,049\n",
      "Trainable params: 1,278,849\n",
      "Non-trainable params: 6,004,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.34 - ETA: 7s - loss: 0.6992 - accuracy: 0.45 - ETA: 8s - loss: 0.6958 - accuracy: 0.48 - ETA: 8s - loss: 0.6891 - accuracy: 0.53 - ETA: 8s - loss: 0.6859 - accuracy: 0.55 - ETA: 8s - loss: 0.6949 - accuracy: 0.53 - ETA: 8s - loss: 0.6946 - accuracy: 0.52 - ETA: 8s - loss: 0.6933 - accuracy: 0.53 - ETA: 8s - loss: 0.6926 - accuracy: 0.53 - ETA: 8s - loss: 0.6919 - accuracy: 0.54 - ETA: 8s - loss: 0.6920 - accuracy: 0.53 - ETA: 8s - loss: 0.6920 - accuracy: 0.53 - ETA: 8s - loss: 0.6904 - accuracy: 0.54 - ETA: 8s - loss: 0.6903 - accuracy: 0.54 - ETA: 7s - loss: 0.6880 - accuracy: 0.55 - ETA: 7s - loss: 0.6896 - accuracy: 0.55 - ETA: 7s - loss: 0.6890 - accuracy: 0.55 - ETA: 7s - loss: 0.6895 - accuracy: 0.55 - ETA: 7s - loss: 0.6879 - accuracy: 0.56 - ETA: 7s - loss: 0.6877 - accuracy: 0.56 - ETA: 7s - loss: 0.6858 - accuracy: 0.56 - ETA: 7s - loss: 0.6835 - accuracy: 0.57 - ETA: 7s - loss: 0.6859 - accuracy: 0.57 - ETA: 7s - loss: 0.6851 - accuracy: 0.57 - ETA: 7s - loss: 0.6834 - accuracy: 0.57 - ETA: 7s - loss: 0.6838 - accuracy: 0.57 - ETA: 7s - loss: 0.6848 - accuracy: 0.57 - ETA: 7s - loss: 0.6849 - accuracy: 0.57 - ETA: 6s - loss: 0.6847 - accuracy: 0.57 - ETA: 6s - loss: 0.6832 - accuracy: 0.57 - ETA: 6s - loss: 0.6838 - accuracy: 0.57 - ETA: 6s - loss: 0.6828 - accuracy: 0.58 - ETA: 6s - loss: 0.6826 - accuracy: 0.58 - ETA: 6s - loss: 0.6816 - accuracy: 0.58 - ETA: 6s - loss: 0.6826 - accuracy: 0.58 - ETA: 6s - loss: 0.6821 - accuracy: 0.58 - ETA: 6s - loss: 0.6822 - accuracy: 0.58 - ETA: 6s - loss: 0.6825 - accuracy: 0.58 - ETA: 6s - loss: 0.6826 - accuracy: 0.58 - ETA: 6s - loss: 0.6823 - accuracy: 0.58 - ETA: 5s - loss: 0.6818 - accuracy: 0.58 - ETA: 5s - loss: 0.6817 - accuracy: 0.58 - ETA: 5s - loss: 0.6812 - accuracy: 0.58 - ETA: 5s - loss: 0.6835 - accuracy: 0.57 - ETA: 5s - loss: 0.6836 - accuracy: 0.57 - ETA: 5s - loss: 0.6842 - accuracy: 0.57 - ETA: 5s - loss: 0.6841 - accuracy: 0.57 - ETA: 5s - loss: 0.6840 - accuracy: 0.57 - ETA: 5s - loss: 0.6840 - accuracy: 0.57 - ETA: 5s - loss: 0.6835 - accuracy: 0.58 - ETA: 5s - loss: 0.6870 - accuracy: 0.57 - ETA: 5s - loss: 0.6871 - accuracy: 0.57 - ETA: 5s - loss: 0.6881 - accuracy: 0.57 - ETA: 4s - loss: 0.6887 - accuracy: 0.57 - ETA: 4s - loss: 0.6886 - accuracy: 0.57 - ETA: 4s - loss: 0.6888 - accuracy: 0.56 - ETA: 4s - loss: 0.6884 - accuracy: 0.57 - ETA: 4s - loss: 0.6877 - accuracy: 0.57 - ETA: 4s - loss: 0.6874 - accuracy: 0.57 - ETA: 4s - loss: 0.6873 - accuracy: 0.57 - ETA: 4s - loss: 0.6868 - accuracy: 0.57 - ETA: 4s - loss: 0.6870 - accuracy: 0.57 - ETA: 4s - loss: 0.6872 - accuracy: 0.57 - ETA: 4s - loss: 0.6864 - accuracy: 0.57 - ETA: 4s - loss: 0.6868 - accuracy: 0.57 - ETA: 3s - loss: 0.6861 - accuracy: 0.57 - ETA: 3s - loss: 0.6859 - accuracy: 0.57 - ETA: 3s - loss: 0.6859 - accuracy: 0.57 - ETA: 3s - loss: 0.6860 - accuracy: 0.57 - ETA: 3s - loss: 0.6853 - accuracy: 0.57 - ETA: 3s - loss: 0.6853 - accuracy: 0.57 - ETA: 3s - loss: 0.6840 - accuracy: 0.57 - ETA: 3s - loss: 0.6834 - accuracy: 0.58 - ETA: 3s - loss: 0.6840 - accuracy: 0.58 - ETA: 3s - loss: 0.6837 - accuracy: 0.57 - ETA: 3s - loss: 0.6834 - accuracy: 0.57 - ETA: 3s - loss: 0.6832 - accuracy: 0.57 - ETA: 2s - loss: 0.6843 - accuracy: 0.57 - ETA: 2s - loss: 0.6831 - accuracy: 0.57 - ETA: 2s - loss: 0.6829 - accuracy: 0.57 - ETA: 2s - loss: 0.6824 - accuracy: 0.57 - ETA: 2s - loss: 0.6823 - accuracy: 0.58 - ETA: 2s - loss: 0.6822 - accuracy: 0.58 - ETA: 2s - loss: 0.6820 - accuracy: 0.58 - ETA: 2s - loss: 0.6822 - accuracy: 0.58 - ETA: 2s - loss: 0.6820 - accuracy: 0.57 - ETA: 2s - loss: 0.6823 - accuracy: 0.58 - ETA: 2s - loss: 0.6819 - accuracy: 0.58 - ETA: 2s - loss: 0.6812 - accuracy: 0.58 - ETA: 2s - loss: 0.6813 - accuracy: 0.58 - ETA: 1s - loss: 0.6808 - accuracy: 0.58 - ETA: 1s - loss: 0.6801 - accuracy: 0.58 - ETA: 1s - loss: 0.6807 - accuracy: 0.58 - ETA: 1s - loss: 0.6804 - accuracy: 0.58 - ETA: 1s - loss: 0.6803 - accuracy: 0.58 - ETA: 1s - loss: 0.6798 - accuracy: 0.58 - ETA: 1s - loss: 0.6786 - accuracy: 0.58 - ETA: 1s - loss: 0.6775 - accuracy: 0.58 - ETA: 1s - loss: 0.6771 - accuracy: 0.58 - ETA: 1s - loss: 0.6768 - accuracy: 0.58 - ETA: 1s - loss: 0.6773 - accuracy: 0.58 - ETA: 1s - loss: 0.6776 - accuracy: 0.58 - ETA: 0s - loss: 0.6770 - accuracy: 0.58 - ETA: 0s - loss: 0.6761 - accuracy: 0.58 - ETA: 0s - loss: 0.6767 - accuracy: 0.58 - ETA: 0s - loss: 0.6758 - accuracy: 0.58 - ETA: 0s - loss: 0.6755 - accuracy: 0.58 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6757 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6756 - accuracy: 0.59 - ETA: 0s - loss: 0.6753 - accuracy: 0.59 - ETA: 0s - loss: 0.6742 - accuracy: 0.59 - ETA: 0s - loss: 0.6729 - accuracy: 0.59 - ETA: 0s - loss: 0.6727 - accuracy: 0.59 - 13s 110ms/step - loss: 0.6727 - accuracy: 0.5950 - val_loss: 0.7071 - val_accuracy: 0.6176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: ba157591418d73702df27424075bdeae</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6176470518112183</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-layer1_units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-layer2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-layer_1: gru</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-layer_2: lstm</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer_name: rmsprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = Hyperband(\n",
    "    Han_hyper,\n",
    "    max_epochs=1,\n",
    "    objective='val_accuracy',\n",
    "    seed = seed_value,\n",
    "    directory=model_name,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(x_train,y_train, epochs=1, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tuner_han.pkl', 'wb') as f:\n",
    "    pickle.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
